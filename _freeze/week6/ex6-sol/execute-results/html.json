{
  "hash": "92c0ead655abb52108888063224e66bc",
  "result": {
    "engine": "knitr",
    "markdown": "---\ntitle: \"Exercise Week 6: Solutions\"\n---\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nlibrary(fpp3)\nlibrary(broom)\n```\n:::\n\n\n\n\n# fpp3 8.8, Ex1\n\n> Consider the the number of pigs slaughtered in Victoria, available in the `aus_livestock` dataset.\n\n>   a. Use the `ETS()` function in R to estimate the equivalent model for simple exponential smoothing. Find the optimal values of $\\alpha$ and $\\ell_0$, and generate forecasts for the next four months.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfit <- aus_livestock |>\n  filter(Animal == \"Pigs\", State == \"Victoria\") |>\n  model(ses = ETS(Count ~ error(\"A\") + trend(\"N\") + season(\"N\")))\nreport(fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\nSeries: Count \nModel: ETS(A,N,N) \n  Smoothing parameters:\n    alpha = 0.3221247 \n\n  Initial states:\n     l[0]\n 100646.6\n\n  sigma^2:  87480760\n\n     AIC     AICc      BIC \n13737.10 13737.14 13750.07 \n```\n\n\n:::\n:::\n\n\n\n\nOptimal values are $\\alpha = 0.3221247$  and $\\ell_0 = 100646.6$\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nfc <- fit |> forecast(h = \"4 months\")\nfc\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A fable: 4 x 6 [1M]\n# Key:     Animal, State, .model [1]\n  Animal State    .model    Month             Count  .mean\n  <fct>  <fct>    <chr>     <mth>            <dist>  <dbl>\n1 Pigs   Victoria ses    2019 Jan N(95187, 8.7e+07) 95187.\n2 Pigs   Victoria ses    2019 Feb N(95187, 9.7e+07) 95187.\n3 Pigs   Victoria ses    2019 Mar N(95187, 1.1e+08) 95187.\n4 Pigs   Victoria ses    2019 Apr N(95187, 1.1e+08) 95187.\n```\n\n\n:::\n\n```{.r .cell-code}\nfc |>\n  autoplot(filter(aus_livestock, Month >= yearmonth(\"2010 Jan\")))\n```\n\n::: {.cell-output-display}\n![](ex6-sol_files/figure-html/ex1b-1.png){width=672}\n:::\n:::\n\n\n\n\n>   b. Compute a 95% prediction interval for the first forecast using $\\hat{y} \\pm 1.96s$ where $s$ is the standard deviation of the residuals. Compare your interval with the interval produced by R.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\ns <- augment(fit) |>\n  pull(.resid) |>\n  sd()\nyhat <- fc |>\n  pull(.mean) |>\n  head(1)\nyhat + c(-1, 1) * 1.96 * s\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]  76871.01 113502.10\n```\n\n\n:::\n:::\n\n::: {.cell}\n\n```{.r .cell-code}\nfc |>\n  head(1) |>\n  mutate(interval = hilo(Count, 95)) |>\n  pull(interval)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n<hilo[1]>\n[1] [76854.79, 113518.3]95\n```\n\n\n:::\n:::\n\n\n\n\nThe intervals are close but not identical. This is because R estimates the variance of the residuals differently, taking account of the degrees of freedom properly (and also using a more accurate critical value rather than just 1.96).\n\nTry the following.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nres <- augment(fit) |> pull(.resid)\ns <- sqrt(sum(res^2) / (length(res) - NROW(tidy(fit))))\nyhat + c(-1, 1) * qnorm(0.975) * s\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1]  76854.79 113518.33\n```\n\n\n:::\n:::\n\n\n\n\n# fpp3 8.8, Ex2\n\n> Write your own function to implement simple exponential smoothing. The function should take arguments `y` (the response data), `alpha` (the smoothing parameter $\\alpha$) and `level` (the initial level $\\ell_0$). It should return the forecast of the next observation in the series. Does it give the same forecast as `ETS()`?\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_ses <- function(y, alpha, level) {\n  yhat <- numeric(length(y) + 1)\n  yhat[1] <- level\n  for (i in 2:(length(yhat))) {\n    yhat[i] <- alpha * y[i - 1] + (1 - alpha) * yhat[i - 1]\n  }\n  return(last(yhat))\n}\n\nvic_pigs_vec <- aus_livestock |>\n  filter(Animal == \"Pigs\", State == \"Victoria\") |>\n  pull(Count)\n\nses_fc <- vic_pigs_vec |>\n  my_ses(alpha = 0.3221, level = 100646.6)\n\nc(my_ses = ses_fc, fable = fc$.mean[1])\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n  my_ses    fable \n95186.59 95186.56 \n```\n\n\n:::\n:::\n\n\n\n\nYes, the same forecasts are obtained. The slight differences are due to rounding of $\\alpha$ and $\\ell_0$.\n\n# fpp3 8.8, Ex3\n\n> Modify your function from the previous exercise to return the sum of squared errors rather than the forecast of the next observation. Then use the `optim()` function to find the optimal values of $\\alpha$ and $\\ell_0$. Do you get the same values as the `ETS()` function?\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_ses_sse <- function(par, y) {\n  alpha <- par[1]\n  level <- par[2]\n  n <- length(y)\n  yhat <- numeric(n)\n  yhat[1] <- level\n  for (i in 2:n) {\n    yhat[i] <- alpha * y[i - 1] + (1 - alpha) * yhat[i - 1]\n  }\n  return(sum((y - yhat)^2))\n}\n\noptim(c(0.1, vic_pigs_vec[1]), my_ses_sse, y = vic_pigs_vec)$par\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 3.220344e-01 1.005254e+05\n```\n\n\n:::\n\n```{.r .cell-code}\ntidy(fit)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n# A tibble: 2 Ã— 5\n  Animal State    .model term    estimate\n  <fct>  <fct>    <chr>  <chr>      <dbl>\n1 Pigs   Victoria ses    alpha      0.322\n2 Pigs   Victoria ses    l[0]  100647.   \n```\n\n\n:::\n:::\n\n\n\n\nSimilar, but not identical estimates. This is due to different starting values being used.\n\n# fpp3 8.8, Ex4\n\n> Combine your previous two functions to produce a function that both finds the optimal values of $\\alpha$ and $\\ell_0$, and produces a forecast of the next observation in the series.\n\n\n\n\n::: {.cell}\n\n```{.r .cell-code}\nmy_ses <- function(y) {\n  par <- optim(c(0.1, y[1]), my_ses_sse, y = y)$par\n  alpha <- par[1]\n  level <- par[2]\n  yhat <- numeric(length(y) + 1)\n  yhat[1] <- level\n  for (i in 2:(length(yhat))) {\n    yhat[i] <- alpha * y[i - 1] + (1 - alpha) * yhat[i - 1]\n  }\n  return(last(yhat))\n}\nmy_ses(vic_pigs_vec)\n```\n\n::: {.cell-output .cell-output-stdout}\n\n```\n[1] 95186.69\n```\n\n\n:::\n:::\n\n\n\n\n# fpp3 8.8, Ex16\n\n> Show that the forecast variance for an ETS(A,N,N) model is given by\n$$\n\\sigma^2\\left[1+\\alpha^2(h-1)\\right].\n$$\n\nAn ETS(A,N,N) model is defined as\n  \\begin{align*}\n    y_t      & = \\ell_{t-1} + \\varepsilon_{t} \\\\\n    \\ell_{t} & = \\ell_{t-1} + \\alpha\\varepsilon_{t},\n  \\end{align*}\nwhere $\\varepsilon_t \\sim \\text{N}(0,\\sigma^2)$, and $h$-step forecasts are  given by\n$$\n \\hat{y}_{T+h|T} = \\ell_T.\n$$\nSo\n  \\begin{align*}\n     y_{T+h} & = \\ell_{T+h-1} + \\varepsilon_{T+h} \\\\\n             & = \\ell_{T+h-2} + \\alpha \\varepsilon_{T+h-1} +  \\varepsilon_{T+h} \\\\\n             & = \\ell_{T+h-3} + \\alpha \\varepsilon_{T+h-2}  + \\alpha \\varepsilon_{T+h-1} +  \\varepsilon_{T+h} \\\\\n             & \\dots \\\\\n             & = \\ell_{T} + \\alpha \\sum_{j=1}^{h-1} \\varepsilon_{T+h-j} +  \\varepsilon_{T+h}.\n  \\end{align*}\nTherefore\n  \\begin{align*}\n    \\text{Var}(y_{T+h} | y_1,\\dots,y_T) & = \\alpha^2 \\sum_{j=1}^{h-1} \\sigma^2 +  \\sigma^2 \\\\\n                                        & =  \\sigma^2\\left[ 1 + \\alpha^2 (h-1)\\right ].\n  \\end{align*}\n\n# fpp3 8.8, Ex17\n\n> Write down 95\\% prediction intervals for an ETS(A,N,N) model as a function of $\\ell_T$, $\\alpha$, $h$ and $\\sigma$, assuming normally distributed errors.\n\nUsing previous result:\n$$\n \\ell_T \\pm 1.96 \\sigma \\sqrt{ 1 + \\alpha^2 (h-1)}\n$$\n",
    "supporting": [
      "ex6-sol_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}